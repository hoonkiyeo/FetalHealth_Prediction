{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Optuna with feature selection of corrleation 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetal = pd.read_csv(\"fetal_health.csv\")\n",
    "corr = fetal.corr()\n",
    "X = fetal[corr[abs(corr['fetal_health']) > 0.15]['fetal_health'].index]\n",
    "X = X.drop(['fetal_health'], axis=1).values\n",
    "y = fetal['fetal_health'].values.ravel().astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=123,\n",
    "                                                    stratify=y)\n",
    "\n",
    "X_train_sub, X_valid, y_train_sub, y_valid = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=123, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 1488 298 638\n"
     ]
    }
   ],
   "source": [
    "print('Train/Valid/Test sizes:', y_train.shape[0], y_valid.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "\n",
    "def optimization_objective(trial, X_train, y_train, cv=5):\n",
    "\n",
    "    \n",
    "    params =  {\n",
    "            \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [30, 50, 100, 300, 500, 1000]),\n",
    "            \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.01, 0.03, 0.05, 0.1]),\n",
    "            \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 1.0),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1.0),\n",
    "    }\n",
    "    \n",
    "\n",
    "    cv_iterator = StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "\n",
    "    cv_scores = np.zeros(cv)\n",
    "    for idx, (train_sub_idx, valid_idx) in enumerate(cv_iterator.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_sub, X_valid = X_train[train_sub_idx], X_train[valid_idx]\n",
    "        y_train_sub, y_valid = y_train[train_sub_idx], y_train[valid_idx]\n",
    "        \n",
    "\n",
    "        model = XGBClassifier(**params, random_state=123, use_label_encoder=False)\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_sub,\n",
    "            y_train_sub,\n",
    "            verbose=False,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric=\"auc\",\n",
    "            early_stopping_rounds=100,\n",
    "        )\n",
    "        \n",
    "        preds = model.score(X_valid, y_valid)\n",
    "        \n",
    "        cv_scores[idx] = preds\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-22 17:30:26,171]\u001b[0m A new study created in memory with name: XGBoost Classifier\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:28,076]\u001b[0m Trial 0 finished with value: 0.9334756965629449 and parameters: {'n_estimators': 50, 'learning_rate': 0.05, 'lambda': 0.07228467045990493, 'alpha': 0.6366909936260661}. Best is trial 0 with value: 0.9334756965629449.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:34,640]\u001b[0m Trial 1 finished with value: 0.9395227442207309 and parameters: {'n_estimators': 500, 'learning_rate': 0.03, 'lambda': 0.0006993359873520448, 'alpha': 1.5246526756953655e-08}. Best is trial 1 with value: 0.9395227442207309.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:40,701]\u001b[0m Trial 2 finished with value: 0.9408672858337287 and parameters: {'n_estimators': 300, 'learning_rate': 0.03, 'lambda': 0.0003199567248724319, 'alpha': 2.40623488649738e-07}. Best is trial 2 with value: 0.9408672858337287.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:43,434]\u001b[0m Trial 3 finished with value: 0.9422163469143335 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'lambda': 0.0023265214222023475, 'alpha': 7.599635321170267e-08}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:45,172]\u001b[0m Trial 4 finished with value: 0.9341513569701488 and parameters: {'n_estimators': 50, 'learning_rate': 0.03, 'lambda': 0.0012595847140170844, 'alpha': 0.00040191794571301545}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:48,324]\u001b[0m Trial 5 finished with value: 0.9361692992565477 and parameters: {'n_estimators': 100, 'learning_rate': 0.03, 'lambda': 0.0010880036881060168, 'alpha': 1.6212187896265546e-08}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:51,152]\u001b[0m Trial 6 finished with value: 0.9422163469143335 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'lambda': 0.0004371094237738491, 'alpha': 8.429966435949566e-06}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:30:55,578]\u001b[0m Trial 7 finished with value: 0.9388561227487402 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 9.562985909124948e-05, 'alpha': 0.3173075133359721}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:02,186]\u001b[0m Trial 8 finished with value: 0.9401916254265247 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'lambda': 4.8180980877367275e-08, 'alpha': 3.1645199468139437e-07}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:05,089]\u001b[0m Trial 9 finished with value: 0.9381872415429463 and parameters: {'n_estimators': 100, 'learning_rate': 0.05, 'lambda': 0.0011390321002495366, 'alpha': 0.02576823982377979}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:17,718]\u001b[0m Trial 10 finished with value: 0.9381849818091428 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'lambda': 0.6401560665315328, 'alpha': 5.792523837119431e-05}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:20,594]\u001b[0m Trial 11 finished with value: 0.9422163469143335 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'lambda': 3.4785764036470054e-06, 'alpha': 7.018605230840924e-06}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:21,886]\u001b[0m Trial 12 finished with value: 0.9355004180507536 and parameters: {'n_estimators': 30, 'learning_rate': 0.1, 'lambda': 1.0518953615009478e-05, 'alpha': 1.8162578803107817e-06}. Best is trial 3 with value: 0.9422163469143335.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:24,638]\u001b[0m Trial 13 finished with value: 0.9435563690597247 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'lambda': 0.017624345263090466, 'alpha': 0.0002332877197100106}. Best is trial 13 with value: 0.9435563690597247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:27,423]\u001b[0m Trial 14 finished with value: 0.9402006643617382 and parameters: {'n_estimators': 100, 'learning_rate': 0.1, 'lambda': 0.048096584222983116, 'alpha': 0.0017673403150873063}. Best is trial 13 with value: 0.9435563690597247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:39,036]\u001b[0m Trial 15 finished with value: 0.9375093214019389 and parameters: {'n_estimators': 1000, 'learning_rate': 0.01, 'lambda': 0.01694521657269837, 'alpha': 0.005113015816518278}. Best is trial 13 with value: 0.9435563690597247.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:44,809]\u001b[0m Trial 16 finished with value: 0.9442275099993221 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.011377833739752685, 'alpha': 8.073870281812572e-05}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:49,766]\u001b[0m Trial 17 finished with value: 0.9422163469143335 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.32056338069941626, 'alpha': 6.520546744669733e-05}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:55,573]\u001b[0m Trial 18 finished with value: 0.9428807086525207 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.011084634938433166, 'alpha': 0.00026882027398706065}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:31:56,777]\u001b[0m Trial 19 finished with value: 0.9254242650215805 and parameters: {'n_estimators': 30, 'learning_rate': 0.01, 'lambda': 2.026889410984263e-05, 'alpha': 0.012704655518935631}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:01,445]\u001b[0m Trial 20 finished with value: 0.9422118274467268 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.010679193355772694, 'alpha': 1.588387941453098e-05}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:06,360]\u001b[0m Trial 21 finished with value: 0.940193885160328 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.00999015684558516, 'alpha': 0.0005233938298791191}. Best is trial 16 with value: 0.9442275099993221.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:11,846]\u001b[0m Trial 22 finished with value: 0.9448986509389193 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.059808857694842926, 'alpha': 0.0003058587360336303}. Best is trial 22 with value: 0.9448986509389193.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:17,544]\u001b[0m Trial 23 finished with value: 0.9442252502655186 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.13938700687331818, 'alpha': 0.002584117190534934}. Best is trial 22 with value: 0.9448986509389193.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:23,510]\u001b[0m Trial 24 finished with value: 0.9408650260999254 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.1509752762607243, 'alpha': 0.07379825145837396}. Best is trial 22 with value: 0.9448986509389193.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:28,429]\u001b[0m Trial 25 finished with value: 0.944903170406526 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.40575113091379916, 'alpha': 0.003031326388554554}. Best is trial 25 with value: 0.944903170406526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:33,479]\u001b[0m Trial 26 finished with value: 0.944903170406526 and parameters: {'n_estimators': 300, 'learning_rate': 0.1, 'lambda': 0.6163547920375793, 'alpha': 0.0014802943221906549}. Best is trial 25 with value: 0.944903170406526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:42,014]\u001b[0m Trial 27 finished with value: 0.9395295234221408 and parameters: {'n_estimators': 300, 'learning_rate': 0.01, 'lambda': 0.9306538022068497, 'alpha': 0.0013062217903016227}. Best is trial 25 with value: 0.944903170406526.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:49,475]\u001b[0m Trial 28 finished with value: 0.9469188529591215 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'lambda': 0.9790017216708068, 'alpha': 0.13228211190131656}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:51,520]\u001b[0m Trial 29 finished with value: 0.9328090750909542 and parameters: {'n_estimators': 50, 'learning_rate': 0.05, 'lambda': 0.9122246587296922, 'alpha': 0.24144595618903644}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:32:58,447]\u001b[0m Trial 30 finished with value: 0.9415429462409328 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'lambda': 3.4217605239024326e-07, 'alpha': 0.05587354488702869}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:05,388]\u001b[0m Trial 31 finished with value: 0.9401916254265247 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'lambda': 0.04622028079619942, 'alpha': 0.009698338501436045}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:12,194]\u001b[0m Trial 32 finished with value: 0.9408650260999254 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'lambda': 0.21989277949973995, 'alpha': 0.6900966121875669}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:18,481]\u001b[0m Trial 33 finished with value: 0.9408672858337287 and parameters: {'n_estimators': 300, 'learning_rate': 0.05, 'lambda': 0.06804989642428155, 'alpha': 0.07318543605081046}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:25,260]\u001b[0m Trial 34 finished with value: 0.9415361670395228 and parameters: {'n_estimators': 300, 'learning_rate': 0.03, 'lambda': 0.3615124723693126, 'alpha': 0.001025498734709888}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:27,017]\u001b[0m Trial 35 finished with value: 0.9381872415429463 and parameters: {'n_estimators': 50, 'learning_rate': 0.1, 'lambda': 0.004212218301413746, 'alpha': 0.003479724751555578}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:36,164]\u001b[0m Trial 36 finished with value: 0.9408718053013354 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03, 'lambda': 0.12169462454243987, 'alpha': 0.0060988236190291}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:37,433]\u001b[0m Trial 37 finished with value: 0.9348247576435496 and parameters: {'n_estimators': 30, 'learning_rate': 0.05, 'lambda': 0.04120420954342906, 'alpha': 0.01847352369094267}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:42,945]\u001b[0m Trial 38 finished with value: 0.9462409328181141 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.4230802518285168, 'alpha': 0.27096699074026437}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:52,683]\u001b[0m Trial 39 finished with value: 0.9402029240955414 and parameters: {'n_estimators': 500, 'learning_rate': 0.03, 'lambda': 0.38668041277295384, 'alpha': 0.19830226609428245}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:33:57,550]\u001b[0m Trial 40 finished with value: 0.9442297697331254 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.4023744983578662, 'alpha': 0.028619676846862643}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:02,776]\u001b[0m Trial 41 finished with value: 0.9388470838135268 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.09785146171180989, 'alpha': 0.7829131147287484}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:08,219]\u001b[0m Trial 42 finished with value: 0.9455743113461235 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.905793876990074, 'alpha': 0.12228636302798804}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:13,736]\u001b[0m Trial 43 finished with value: 0.94557205161232 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.6792972730961669, 'alpha': 0.17385857510833255}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:19,116]\u001b[0m Trial 44 finished with value: 0.9449009106727229 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.9982108033066555, 'alpha': 0.14510364391158617}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:24,415]\u001b[0m Trial 45 finished with value: 0.9442297697331254 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 0.1876408048753896, 'alpha': 0.2966341835164839}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:30,839]\u001b[0m Trial 46 finished with value: 0.9428874878539307 and parameters: {'n_estimators': 500, 'learning_rate': 0.05, 'lambda': 0.00032495210177021735, 'alpha': 0.04847310646078674}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:35,573]\u001b[0m Trial 47 finished with value: 0.9408627663661221 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 1.306791844112272e-08, 'alpha': 0.9308828295745731}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:48,459]\u001b[0m Trial 48 finished with value: 0.9395250039545342 and parameters: {'n_estimators': 500, 'learning_rate': 0.01, 'lambda': 0.9562366324560712, 'alpha': 0.0985152685020703}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n",
      "\u001b[32m[I 2021-11-22 17:34:53,944]\u001b[0m Trial 49 finished with value: 0.94221408718053 and parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'lambda': 9.245143448979058e-05, 'alpha': 0.3586789271080785}. Best is trial 28 with value: 0.9469188529591215.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 0.94692\n",
      "Best params:\n",
      "\tn_estimators: 300\n",
      "\tlearning_rate: 0.05\n",
      "\tlambda: 0.9790017216708068\n",
      "\talpha: 0.13228211190131656\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"XGBoost Classifier\")\n",
    "\n",
    "def func(trial):\n",
    "    return optimization_objective(trial, X_train, y_train)\n",
    "\n",
    "study.optimize(func, n_trials=50);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Best CV accuracy: {study.best_value:.5f}\")\n",
    "print(\"Best params:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.000%\n",
      "Test Accuracy: 94.514%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(**study.best_params, random_state=123, use_label_encoder=False)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=False,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {model.score(X_train, y_train)*100:0.3f}%\")\n",
    "print(f\"Test Accuracy: {model.score(X_test, y_test)*100:0.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
